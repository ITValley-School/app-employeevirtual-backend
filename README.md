# EmployeeVirtual Backend

Sistema backend completo desenvolvido em **Python** com **FastAPI** para a plataforma EmployeeVirtual - Uma soluÃ§Ã£o robusta para criaÃ§Ã£o e gerenciamento de agentes de IA, automaÃ§Ãµes inteligentes e chat conversacional.

## ğŸ¯ VisÃ£o Geral

O EmployeeVirtual Backend Ã© uma API REST que oferece funcionalidades avanÃ§adas para:

- **ğŸ¤– Agentes de IA Personalizados** - CriaÃ§Ã£o, configuraÃ§Ã£o e execuÃ§Ã£o de agentes inteligentes usando PydanticAI
- **ğŸ”„ AutomaÃ§Ãµes (Flows)** - Sistema completo de workflows automatizados para processos complexos
- **ğŸ’¬ Chat Inteligente** - Sistema de conversaÃ§Ã£o avanÃ§ado com histÃ³rico e contexto
- **ğŸ“Š Dashboard e MÃ©tricas** - AnÃ¡lise detalhada de uso, produtividade e performance
- **ğŸ“ Processamento de Arquivos** - Upload e processamento inteligente com IA (OCR, transcriÃ§Ã£o, anÃ¡lise)
- **ğŸ”— IntegraÃ§Ã£o Orion** - ServiÃ§os de IA prontos para uso empresarial
- **ğŸ” AutenticaÃ§Ã£o JWT** - Sistema seguro de autenticaÃ§Ã£o e autorizaÃ§Ã£o
- **ğŸ—„ï¸ Banco de Dados HÃ­brido** - SQL Server/Azure SQL + MongoDB para mÃ¡xima flexibilidade

## ğŸ—ï¸ Arquitetura do Sistema

### Estrutura de Pastas

```
employeevirtual_backend/
â”œâ”€â”€ ï¿½ api/                     # Endpoints da API REST
â”‚   â”œâ”€â”€ auth_api.py            # AutenticaÃ§Ã£o e gestÃ£o de usuÃ¡rios
â”‚   â”œâ”€â”€ agent_api.py           # GestÃ£o de agentes de IA
â”‚   â”œâ”€â”€ flow_api.py            # AutomaÃ§Ãµes e workflows
â”‚   â”œâ”€â”€ chat_api.py            # Sistema de chat/conversaÃ§Ã£o
â”‚   â”œâ”€â”€ dashboard_api.py       # MÃ©tricas e analytics
â”‚   â””â”€â”€ file_api.py            # Upload e processamento de arquivos
â”œâ”€â”€ ğŸ“ data/                    # Camada de dados
â”‚   â”œâ”€â”€ database.py            # ConfiguraÃ§Ã£o SQL Server/Azure SQL
â”‚   â””â”€â”€ mongodb.py             # ConfiguraÃ§Ã£o MongoDB
â”œâ”€â”€ ğŸ“ middlewares/             # Middlewares da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ cors_middleware.py     # CORS para frontend
â”‚   â”œâ”€â”€ logging_middleware.py  # Sistema de logs
â”‚   â””â”€â”€ auth_middleware.py     # AutenticaÃ§Ã£o e rate limiting
â”œâ”€â”€ ğŸ“ models/                  # Modelos de dados (Pydantic + SQLAlchemy)
â”‚   â”œâ”€â”€ user_models.py         # Modelos de usuÃ¡rios
â”‚   â”œâ”€â”€ agent_models.py        # Modelos de agentes
â”‚   â”œâ”€â”€ flow_models.py         # Modelos de flows
â”‚   â”œâ”€â”€ chat_models.py         # Modelos de chat
â”‚   â”œâ”€â”€ dashboard_models.py    # Modelos de dashboard
â”‚   â””â”€â”€ file_models.py         # Modelos de arquivos
â”œâ”€â”€ ğŸ“ services/                # LÃ³gica de negÃ³cio
â”‚   â”œâ”€â”€ user_service.py        # ServiÃ§os de usuÃ¡rio
â”‚   â”œâ”€â”€ agent_service.py       # ServiÃ§os de agentes
â”‚   â”œâ”€â”€ flow_service.py        # ServiÃ§os de flows
â”‚   â”œâ”€â”€ chat_service.py        # ServiÃ§os de chat
â”‚   â”œâ”€â”€ dashboard_service.py   # ServiÃ§os de dashboard
â”‚   â””â”€â”€ orion_service.py       # IntegraÃ§Ã£o com serviÃ§os Orion
â”œâ”€â”€ main.py                     # AplicaÃ§Ã£o principal
â”œâ”€â”€ requirements.txt            # DependÃªncias Python
â”œâ”€â”€ API_DOCUMENTATION.md       # DocumentaÃ§Ã£o completa da API
â”œâ”€â”€ database_schema.sql        # Schema do banco de dados
â””â”€â”€ README.md                  # Este arquivo
```

## ğŸš€ Tecnologias e DependÃªncias

### Core Framework
- **FastAPI 0.104.1** - Framework web moderno e rÃ¡pido
- **Uvicorn 0.24.0** - Servidor ASGI de alta performance
- **Pydantic 2.5.0** - ValidaÃ§Ã£o de dados e serializaÃ§Ã£o
- **PydanticAI 0.0.12** - Framework para agentes de IA

### Banco de Dados
- **SQLAlchemy 2.0.23** - ORM para SQL Server/Azure SQL
- **PyODBC 5.0.1** - Driver para SQL Server
- **PyMongo 4.6.0** - Driver para MongoDB
- **Motor 3.3.2** - Driver assÃ­ncrono para MongoDB

### AutenticaÃ§Ã£o e SeguranÃ§a
- **PyJWT 2.8.0** - Tokens JWT
- **Passlib 1.7.4** - Hash de senhas
- **Python-jose 3.3.0** - Criptografia JWT

### IntegraÃ§Ãµes e Cliente HTTP
- **HTTPx** - Cliente HTTP assÃ­ncrono moderno (integrado ao FastAPI)
- **FastAPI TestClient** - Cliente para testes de integraÃ§Ã£o

## ğŸ¤– Provedores de LLM e Modelos Suportados

O EmployeeVirtual Backend suporta uma ampla gama de provedores de LLM e modelos de IA, oferecendo flexibilidade total para escolher a melhor soluÃ§Ã£o para cada caso de uso.

### ğŸ¢ Provedores Suportados

| Provedor | CÃ³digo | DescriÃ§Ã£o | Status |
|----------|--------|-----------|---------|
| **OpenAI** | `openai` | GPT-4, GPT-3.5, O1, O3 e variaÃ§Ãµes | âœ… Ativo |
| **Anthropic** | `anthropic` | Claude 3.5, Claude 4, Opus, Sonnet, Haiku | âœ… Ativo |
| **Google** | `google` | Gemini 1.5, Gemini 2.0, Gemini 2.5 (GLA/Vertex) | âœ… Ativo |
| **Groq** | `groq` | Llama, Gemma, Whisper, TTS | âœ… Ativo |
| **Ollama** | `ollama` | Modelos locais auto-hospedados | âœ… Ativo |
| **Mistral** | `mistral` | Mistral Large, Small, Codestral | âœ… Ativo |
| **Cohere** | `cohere` | Command R/R+, Aya Expanse | âœ… Ativo |
| **DeepSeek** | `deepseek` | DeepSeek Chat, DeepSeek Reasoner | âœ… Ativo |
| **Azure OpenAI** | `azure` | Modelos OpenAI via Azure | âœ… Ativo |

### ğŸ¯ Modelos Principais por Categoria

#### **ğŸ’¬ ConversaÃ§Ã£o e Chat**
- **OpenAI**: `gpt-4o`, `gpt-4o-mini`, `gpt-4-turbo`, `chatgpt-4o-latest`
- **Anthropic**: `claude-3-5-sonnet-latest`, `claude-4-sonnet-20250514`, `claude-3-5-haiku-latest`
- **Google**: `gemini-2.0-flash`, `gemini-2.5-pro`, `gemini-1.5-pro`
- **Groq**: `llama-3.3-70b-versatile`, `llama-3.1-8b-instant`

#### **ğŸ§  RaciocÃ­nio AvanÃ§ado**
- **OpenAI**: `o1`, `o1-mini`, `o3`, `o3-mini`
- **DeepSeek**: `deepseek-reasoner`
- **Groq**: `qwen-qwq-32b`, `deepseek-r1-distill-qwen-32b`

#### **ğŸ’» ProgramaÃ§Ã£o e CÃ³digo**
- **Mistral**: `codestral-latest`
- **Groq**: `qwen-2.5-coder-32b`
- **Anthropic**: `claude-3-5-sonnet-20241022` (excelente para cÃ³digo)

#### **ğŸµ Ãudio e Voz**
- **OpenAI**: `gpt-4o-audio-preview`, `gpt-4o-mini-audio-preview`
- **Groq**: `whisper-large-v3`, `whisper-large-v3-turbo`, `playai-tts`

#### **ğŸ” Busca e Pesquisa**
- **OpenAI**: `gpt-4o-search-preview`, `gpt-4o-mini-search-preview`

#### **ğŸ‘ï¸ VisÃ£o Computacional**
- **OpenAI**: `gpt-4-vision-preview`, `gpt-4o` (com visÃ£o)
- **Groq**: `llama-3.2-11b-vision-preview`, `llama-3.2-90b-vision-preview`

### ğŸ“‹ Lista Completa de Modelos Suportados

#### **OpenAI Models**
```
gpt-3.5-turbo, gpt-3.5-turbo-0125, gpt-3.5-turbo-16k
gpt-4, gpt-4-turbo, gpt-4-32k, gpt-4o, gpt-4o-mini
gpt-4o-audio-preview, gpt-4o-search-preview
gpt-4.1, gpt-4.1-mini, gpt-4.1-nano
o1, o1-mini, o1-preview
o3, o3-mini, o4-mini
chatgpt-4o-latest
```

#### **Anthropic Models**
```
claude-2.0, claude-2.1
claude-3-haiku-20240307, claude-3-sonnet-20240229, claude-3-opus-20240229
claude-3-5-haiku-20241022, claude-3-5-sonnet-20240620, claude-3-5-sonnet-20241022
claude-3-7-sonnet-20250219
claude-4-opus-20250514, claude-4-sonnet-20250514
claude-opus-4-0, claude-sonnet-4-0
```

#### **Google Models**
```
# Google AI Studio (GLA)
gemini-1.0-pro, gemini-1.5-flash, gemini-1.5-flash-8b, gemini-1.5-pro
gemini-2.0-flash, gemini-2.0-flash-lite-preview, gemini-2.0-pro-exp
gemini-2.5-flash, gemini-2.5-pro, gemini-2.5-flash-lite-preview

# Google Vertex AI
google-vertex:gemini-1.5-pro, google-vertex:gemini-2.0-flash
google-vertex:gemini-2.5-pro, google-vertex:gemini-2.5-flash
```

#### **Groq Models**
```
# LLM Models
llama-3.3-70b-versatile, llama-3.1-8b-instant, llama3-70b-8192
qwen-qwq-32b, qwen-2.5-coder-32b, qwen-2.5-32b
mistral-saba-24b, gemma2-9b-it
deepseek-r1-distill-qwen-32b, deepseek-r1-distill-llama-70b

# Audio Models
whisper-large-v3, whisper-large-v3-turbo, distil-whisper-large-v3-en
playai-tts, playai-tts-arabic

# Vision Models  
llama-3.2-11b-vision-preview, llama-3.2-90b-vision-preview

# Other Sizes
llama-3.2-1b-preview, llama-3.2-3b-preview
```

#### **Mistral Models**
```
mistral-large-latest, mistral-small-latest
codestral-latest, mistral-moderation-latest
```

#### **Cohere Models**
```
command, command-light, command-nightly
command-r, command-r-plus, command-r7b-12-2024
c4ai-aya-expanse-32b, c4ai-aya-expanse-8b
```

#### **DeepSeek Models**
```
deepseek-chat, deepseek-reasoner
```

#### **AWS Bedrock Models**
```
# Amazon
amazon.titan-tg1-large, amazon.titan-text-lite-v1
us.amazon.nova-pro-v1:0, us.amazon.nova-lite-v1:0

# Anthropic on Bedrock
anthropic.claude-3-5-sonnet-20241022-v2:0
anthropic.claude-3-5-haiku-20241022-v1:0
anthropic.claude-3-opus-20240229-v1:0

# Meta Llama on Bedrock
meta.llama3-1-70b-instruct-v1:0
us.meta.llama3-2-90b-instruct-v1:0
us.meta.llama3-3-70b-instruct-v1:0

# Mistral on Bedrock
mistral.mistral-large-2407-v1:0
mistral.mixtral-8x7b-instruct-v0:1
```

### âš™ï¸ Como Configurar Modelos nos Agentes

#### **1. CriaÃ§Ã£o de Agente com Modelo EspecÃ­fico**
```json
{
  "name": "Assistente GPT-4",
  "description": "Agente usando GPT-4o para tarefas complexas",
  "llm_provider": "openai",
  "model": "gpt-4o",
  "temperature": 0.7,
  "max_tokens": 4000,
  "system_prompt": "VocÃª Ã© um assistente especializado..."
}
```

#### **2. Formato do Modelo no Sistema**
Os modelos sÃ£o salvos no formato `provider:model` internamente:
- `openai:gpt-4o`
- `anthropic:claude-3-5-sonnet-latest`
- `google:gemini-2.0-flash`
- `groq:llama-3.3-70b-versatile`

#### **3. ConfiguraÃ§Ãµes Recomendadas por Caso de Uso**

| Caso de Uso | Modelo Recomendado | Temperature | Max Tokens |
|-------------|-------------------|-------------|------------|
| **Chat Geral** | `gpt-4o-mini` | 0.7 | 2000 |
| **AnÃ¡lise Complexa** | `claude-3-5-sonnet-latest` | 0.3 | 4000 |
| **CÃ³digo/ProgramaÃ§Ã£o** | `codestral-latest` | 0.1 | 8000 |
| **RaciocÃ­nio** | `o1-mini` | 1.0 | 32000 |
| **Respostas RÃ¡pidas** | `llama-3.1-8b-instant` | 0.8 | 1000 |
| **Criativo** | `claude-3-5-haiku-latest` | 0.9 | 2000 |

### ğŸ”§ ConfiguraÃ§Ã£o de Provedores

Para usar diferentes provedores, configure as variÃ¡veis de ambiente:

```bash
# OpenAI
OPENAI_API_KEY=your_openai_key

# Anthropic  
ANTHROPIC_API_KEY=your_anthropic_key

# Google
GOOGLE_API_KEY=your_google_key

# Groq
GROQ_API_KEY=your_groq_key

# Azure OpenAI
AZURE_OPENAI_API_KEY=your_azure_key
AZURE_OPENAI_ENDPOINT=your_azure_endpoint

# Outros provedores conforme necessÃ¡rio
```

