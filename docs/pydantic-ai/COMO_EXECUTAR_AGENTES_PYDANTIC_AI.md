# ü§ñ Como Executar Agentes de IA Pydantic - EmployeeVirtual## üìã Vis√£o GeralEste guia completo mostra como usar os agentes de IA do EmployeeVirtual que foram implementados com **Pydantic AI**. Os agentes suportam 50+ modelos LLM de diferentes provedores e oferecem funcionalidades avan√ßadas como tools, dependency injection e structured output.---## üöÄ Configura√ß√£o Inicial### 1. **Vari√°veis de Ambiente**Configure as chaves de API dos provedores LLM:```bash# OpenAIOPENAI_API_KEY=sk-your_openai_key_here# AnthropicANTHROPIC_API_KEY=sk-ant-your_anthropic_key# GoogleGOOGLE_API_KEY=your_google_ai_key# GroqGROQ_API_KEY=gsk_your_groq_key# Azure OpenAIAZURE_OPENAI_API_KEY=your_azure_keyAZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/# Outros provedoresMISTRAL_API_KEY=your_mistral_keyCOHERE_API_KEY=your_cohere_keyDEEPSEEK_API_KEY=your_deepseek_key```### 2. **Depend√™ncias**```bashpip install pydantic-ai httpx sqlalchemy```---## üéØ Criando um Agente### **1. Endpoint: `POST /api/agents/`**```pythonimport requests# Dados do agenteagent_data = {    "name": "Assistente GPT-4",    "description": "Agente especializado em an√°lise e conversa√ß√£o",    "agent_type": "custom",    "llm_provider": "openai",    "model": "gpt-4o",    "temperature": 0.7,    "max_tokens": 4000,    "system_prompt": "Voc√™ √© um assistente especializado em an√°lise de dados e conversa√ß√£o inteligente. Seja preciso, √∫til e educado.",    "personality": "Amig√°vel, profissional e detalhista"}# Headers com autentica√ß√£oheaders = {    "Authorization": "Bearer seu_token_aqui",    "Content-Type": "application/json"}# Criar agenteresponse = requests.post(    "http://localhost:8000/api/agents/",    json=agent_data,    headers=headers)agent = response.json()print(f"Agente criado: ID {agent['id']} - {agent['name']}")```### **2. Via Python Direto**```pythonfrom services.agent_service import AgentServicefrom models.agent_models import AgentCreatefrom data.database import get_db# Configurar sess√£o do bancodb = next(get_db())agent_service = AgentService(db)# Criar agenteagent_data = AgentCreate(    name="Assistente Claude",    description="Agente com Claude 3.5 Sonnet",    llm_provider="anthropic",    model="claude-3-5-sonnet-latest",    temperature=0.3,    max_tokens=8000,    system_prompt="Voc√™ √© um assistente especializado em programa√ß√£o e an√°lise t√©cnica.")agent = agent_service.create_agent(user_id=123, agent_data=agent_data)print(f"Agente criado: {agent.name}")```---## üî• Executando Agentes### **1. Execu√ß√£o B√°sica - API**```pythonimport requests# Dados da execu√ß√£oexecution_data = {    "user_message": "Explique o que √© machine learning em termos simples",    "context": {        "source": "api_request",        "timestamp": "2025-01-15T10:30:00Z"    }}headers = {    "Authorization": "Bearer seu_token_aqui",    "Content-Type": "application/json"}# Executar agenteresponse = requests.post(    f"http://localhost:8000/api/agents/{agent_id}/execute",    json=execution_data,    headers=headers)result = response.json()print(f"Resposta: {result['response']}")print(f"Tempo de execu√ß√£o: {result['execution_time']:.2f}s")print(f"Modelo usado: {result['model_used']}")```### **2. Execu√ß√£o via Python**```python# Execu√ß√£o direta no c√≥digoresult = await agent_service.execute_agent(    agent_id=1,    user_id=123,    user_message="Analise este relat√≥rio e me d√™ insights",    context={        "file_url": "https://example.com/relatorio.pdf",        "analysis_type": "business_intelligence",        "priority": "high"    })# Resultadoprint(f"Resposta: {result['response']}")print(f"Sucesso: {result['success']}")print(f"Tempo: {result['execution_time']:.2f}s")print(f"Modelo: {result['model_used']}")```---## üõ†Ô∏è Modelos LLM Suportados### **Modelos Principais por Categoria**| **Categoria** | **Modelo Recomendado** | **Provedor** | **Uso** ||---------------|------------------------|--------------|---------|| **Chat Geral** | `gpt-4o-mini` | OpenAI | Conversa√ß√£o r√°pida e econ√¥mica || **An√°lise Complexa** | `claude-3-5-sonnet-latest` | Anthropic | Racioc√≠nio avan√ßado || **Programa√ß√£o** | `codestral-latest` | Mistral | C√≥digo e desenvolvimento || **Racioc√≠nio** | `o1-mini` | OpenAI | Problemas complexos || **Respostas R√°pidas** | `llama-3.1-8b-instant` | Groq | Velocidade m√°xima || **Criativo** | `claude-3-5-haiku-latest` | Anthropic | Conte√∫do criativo |### **Lista Completa de Provedores**- **OpenAI**: GPT-4o, GPT-4o-mini, O1, O3, ChatGPT-4o-latest- **Anthropic**: Claude 3.5 Sonnet, Claude 4, Haiku, Opus- **Google**: Gemini 2.0/2.5 Flash/Pro- **Groq**: Llama 3.3, Qwen, Whisper, Vision models- **Mistral**: Large, Small, Codestral- **Cohere**: Command R/R+, Aya Expanse- **DeepSeek**: Chat, Reasoner---## üéõÔ∏è Configura√ß√µes de Agentes### **Par√¢metros Importantes**```pythonagent_config = {    # Par√¢metros do modelo    "temperature": 0.7,      # 0.0-2.0: Criatividade (0=determin√≠stico, 2=muito criativo)    "max_tokens": 4000,      # Limite de tokens de resposta        # Configura√ß√µes do agente    "llm_provider": "openai", # Provedor: openai, anthropic, google, groq, etc.    "model": "gpt-4o",       # Modelo espec√≠fico        # Personaliza√ß√£o    "personality": "Amig√°vel e profissional",    "system_prompt": "Voc√™ √© um especialista em...",}```### **Configura√ß√µes Recomendadas por Uso**```python# Para an√°lise de dadosanalysis_config = {    "llm_provider": "anthropic",    "model": "claude-3-5-sonnet-latest",    "temperature": 0.3,  # Baixa para precis√£o    "max_tokens": 8000}# Para conversa√ß√£o casualchat_config = {    "llm_provider": "openai",     "model": "gpt-4o-mini",    "temperature": 0.7,  # M√©dia para naturalidade    "max_tokens": 2000}# Para programa√ß√£ocode_config = {    "llm_provider": "mistral",    "model": "codestral-latest",     "temperature": 0.1,  # Muito baixa para precis√£o    "max_tokens": 8000}# Para criatividadecreative_config = {    "llm_provider": "anthropic",    "model": "claude-3-5-haiku-latest",    "temperature": 0.9,  # Alta para criatividade    "max_tokens": 4000}```---## üìä Gerenciamento de Agentes### **1. Listar Agentes**```python# Via APIresponse = requests.get(    "http://localhost:8000/api/agents/",    headers=headers,    params={"include_system": True})agents = response.json()for agent in agents:    print(f"ID: {agent['id']} | Nome: {agent['name']} | Modelo: {agent['llm_provider']}:{agent['model']}")```### **2. Atualizar Agente**```pythonupdate_data = {    "name": "Assistente GPT-4 Melhorado",    "temperature": 0.5,    "system_prompt": "Prompt atualizado com novas instru√ß√µes..."}response = requests.put(    f"http://localhost:8000/api/agents/{agent_id}",    json=update_data,    headers=headers)```### **3. Hist√≥rico de Execu√ß√µes**```python# Buscar √∫ltimas execu√ß√µesresponse = requests.get(    f"http://localhost:8000/api/agents/{agent_id}/executions",    headers=headers,    params={"limit": 10})executions = response.json()for exec in executions:    print(f"[{exec['created_at']}] {exec['user_message'][:50]}...")    print(f"  Resposta: {exec['response'][:100]}...")    print(f"  Sucesso: {exec['success']} | Tempo: {exec['execution_time']:.2f}s\n")```---## üß† Base de Conhecimento (RAG)### **1. Adicionar Conhecimento**```pythonknowledge_data = {    "file_name": "manual_empresa.pdf",    "file_type": "pdf",     "file_size": 2048576,  # bytes    "file_url": "https://storage.com/manual_empresa.pdf",    "orion_file_id": "orion_123456"  # opcional - para integra√ß√£o ORION}response = requests.post(    f"http://localhost:8000/api/agents/{agent_id}/knowledge",    json=knowledge_data,    headers=headers)knowledge = response.json()print(f"Conhecimento adicionado: {knowledge['file_name']}")```### **2. Usar Conhecimento na Execu√ß√£o**```python# O agente automaticamente usa o conhecimento adicionadoresult = await agent_service.execute_agent(    agent_id=1,    user_id=123,    user_message="Com base no manual da empresa, explique o processo de f√©rias")# O sistema busca automaticamente no conhecimento e inclui no contextoprint(f"Resposta baseada no conhecimento: {result['response']}")```---## üîß Integra√ß√£o com ORION### **Processamento Autom√°tico de Arquivos**```python# O agente pode processar arquivos automaticamente via ORIONresult = await agent_service.execute_agent(    agent_id=1,    user_id=123,    user_message="Transcreva este √°udio e me d√™ um resumo",    context={        "file_url": "https://example.com/audio.mp3",        "process_type": "whisper",  # whisper, ocr, pdf, youtube_transcriber    })print(f"Resultado com processamento ORION: {result['response']}")```### **Tipos de Processamento ORION Suportados**- **`whisper`**: Transcri√ß√£o de √°udio/v√≠deo- **`ocr`**: Extra√ß√£o de texto de imagens  
- **`pdf`**: Processamento de documentos PDF
- **`youtube_transcriber`**: Transcri√ß√£o de v√≠deos do YouTube

---

## üí° Exemplos Pr√°ticos

### **1. Assistente de An√°lise de Dados**

```python
# Criar agente especializado
agent_data = {
    "name": "Analista de Dados",
    "llm_provider": "anthropic",
    "model": "claude-3-5-sonnet-latest",
    "temperature": 0.3,
    "system_prompt": """
    Voc√™ √© um especialista em an√°lise de dados e business intelligence.
    - Analise dados de forma clara e objetiva
    - Forne√ßa insights acion√°veis
    - Use visualiza√ß√µes quando necess√°rio
    - Explique metodologias usadas
    """
}

# Executar an√°lise
result = await agent_service.execute_agent(
    agent_id=agent['id'],
    user_id=123,
    user_message="Analise as vendas do Q4 e identifique tend√™ncias",
    context={"data_source": "sales_q4.csv"}
)
```

### **2. Assistente de C√≥digo**

```python
# Agente para programa√ß√£o
agent_data = {
    "name": "Dev Assistant",
    "llm_provider": "mistral", 
    "model": "codestral-latest",
    "temperature": 0.1,
    "system_prompt": """
    Voc√™ √© um assistente especializado em programa√ß√£o.
    - Escreva c√≥digo limpo e bem documentado
    - Explique conceitos t√©cnicos claramente
    - Sugira melhorias e otimiza√ß√µes
    - Siga boas pr√°ticas de desenvolvimento
    """
}

# Pedir ajuda com c√≥digo
result = await agent_service.execute_agent(
    agent_id=agent['id'],
    user_id=123,
    user_message="Crie uma fun√ß√£o Python para validar CPF"
)
```

### **3. Assistente Multimodal**

```python
# Agente que processa imagens e √°udio
result = await agent_service.execute_agent(
    agent_id=1,
    user_id=123,
    user_message="Analise esta imagem e extraia o texto, depois me d√™ um resumo",
    context={
        "file_url": "https://example.com/documento.jpg",
        "process_type": "ocr"
    }
)

print(f"An√°lise multimodal: {result['response']}")
```

---

## üö® Tratamento de Erros

### **C√≥digos de Erro Comuns**

```python
try:
    result = await agent_service.execute_agent(agent_id, user_id, message)
    
    if result['success']:
        print(f"‚úÖ Sucesso: {result['response']}")
    else:
        print(f"‚ùå Erro: {result['error_message']}")
        
except ValueError as e:
    if "n√£o encontrado" in str(e):
        print("‚ùå Agente n√£o existe ou n√£o pertence ao usu√°rio")
    elif "n√£o est√° ativo" in str(e):
        print("‚ùå Agente est√° inativo")
    elif "Mensagem n√£o pode estar vazia" in str(e):
        print("‚ùå Mensagem √© obrigat√≥ria")
    else:
        print(f"‚ùå Erro de valida√ß√£o: {e}")
        
except Exception as e:
    print(f"‚ùå Erro inesperado: {e}")
```

---

## üìà Monitoramento

### **1. Estat√≠sticas do Agente**

```python
# Via API
response = requests.get(f"http://localhost:8000/api/agents/{agent_id}", headers=headers)
agent = response.json()

print(f"Uso total: {agent['usage_count']} execu√ß√µes")
print(f"√öltimo uso: {agent['last_used']}")
print(f"Status: {agent['status']}")
```

### **2. Performance**

```python
# M√©tricas de execu√ß√£o
executions = requests.get(f"http://localhost:8000/api/agents/{agent_id}/executions", headers=headers).json()

total_time = sum(e['execution_time'] for e in executions)
avg_time = total_time / len(executions) if executions else 0
success_rate = sum(1 for e in executions if e['success']) / len(executions) if executions else 0

print(f"Tempo m√©dio: {avg_time:.2f}s")
print(f"Taxa de sucesso: {success_rate:.1%}")
```

---

## üéâ Resumo de Comandos R√°pidos

### **Workflow Completo**

```python
from services.agent_service import AgentService
from models.agent_models import AgentCreate

# 1. Inicializar servi√ßo
agent_service = AgentService(db)

# 2. Criar agente
agent_data = AgentCreate(
    name="Meu Assistente",
    llm_provider="openai",
    model="gpt-4o-mini", 
    system_prompt="Voc√™ √© um assistente √∫til."
)
agent = agent_service.create_agent(user_id=123, agent_data=agent_data)

# 3. Executar
result = await agent_service.execute_agent(
    agent_id=agent.id,
    user_id=123,
    user_message="Ol√°, como voc√™ pode me ajudar?"
)

# 4. Verificar resultado
print(f"Resposta: {result['response']}")
print(f"Tempo: {result['execution_time']:.2f}s")
```

### **Via API - Comando √önico**

```bash
# Criar e executar agente via curl
curl -X POST "http://localhost:8000/api/agents/" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Test Agent",
    "llm_provider": "openai",
    "model": "gpt-4o-mini",
    "system_prompt": "Voc√™ √© um assistente √∫til.",
    "temperature": 0.7
  }'

# Executar agente
curl -X POST "http://localhost:8000/api/agents/1/execute" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"user_message": "Explique quantum computing"}'
```

---

## üîÆ Recursos Avan√ßados Futuros

- **Streaming de Respostas**: Respostas em tempo real
- **Multi-Agent Conversations**: Agentes colaborando
- **Custom Tools**: Ferramentas personalizadas
- **Instrumenta√ß√£o com Logfire**: Monitoring avan√ßado
- **RAG Avan√ßado**: Busca sem√¢ntica aprimorada

---

**üöÄ Parab√©ns! Agora voc√™ domina os agentes Pydantic AI do EmployeeVirtual!**

Para d√∫vidas ou suporte, consulte a documenta√ß√£o da API completa ou entre em contato com a equipe de desenvolvimento.
